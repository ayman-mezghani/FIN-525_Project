{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pydot\n",
    "#!pip install graphviz\n",
    "\n",
    "#Supposer afficher un sankey hyper style mais ca veut pas mdr\n",
    "#states = [\"0\",\"1\",\"2\",\"3\"]\n",
    "#def _get_markov_edges(Q):\n",
    "#    edges = {}\n",
    "#    for col in Q.columns:\n",
    "#        for idx in Q.index:\n",
    "#            edges[(idx,col)] = Q.loc[idx,col]\n",
    "#    return edges\n",
    "\n",
    "#edges_wts = _get_markov_edges(prob_state_transitions)\n",
    "\n",
    "# create graph object\n",
    "#G = nx.MultiDiGraph()\n",
    "\n",
    "# nodes correspond to states\n",
    "#G.add_nodes_from(states)\n",
    "\n",
    "# edges represent transition probabilities\n",
    "#for k, v in edges_wts.items():\n",
    "#    tmp_origin, tmp_destination = k[0], k[1]\n",
    "#    G.add_edge(tmp_origin, tmp_destination, weight=v, label=v)\n",
    "#, prog='dot'\n",
    "#nx.drawing.nx_pydot.write_dot(G,path=os.environ[\"PATH\"])\n",
    "#pos = nx.drawing.nx_pydot.pydot_layout(G,prog=\"dot\")\n",
    "#nx.draw_networkx(G, pos)\n",
    "\n",
    "# create edge labels for jupyter plot but is not necessary\n",
    "#edge_labels = {(n1,n2):d['label'] for n1,n2,d in G.edges(data=True)}\n",
    "#nx.draw_networkx_edge_labels(G , pos, edge_labels=edge_labels)\n",
    "#nx.drawing.nx_pydot.write_dot(G, 'pet_dog_markov.dot')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Supposer afficher un plot sympa mais ca veut pas mdr\n",
    "\n",
    "\n",
    "#weigted_edges=[]\n",
    "#for i in range(4):\n",
    "#    for j in range(4):\n",
    "#        weigted_edges.append((i,j,prob_state_transitions[i][j]))\n",
    "\n",
    "\n",
    "# create graph object\n",
    "#G = nx.MultiDiGraph()\n",
    "\n",
    "# nodes correspond to states\n",
    "#G.add_nodes_from(states)\n",
    "#G.add_weighted_edges_from(weigted_edges)\n",
    "\n",
    "#nx.draw(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create sankey plot\n",
    "#!pip install plotly\n",
    "#Pour voir comment ca marche\n",
    "#Affiche un graphe de transition donc c'est plutot cool\n",
    "\n",
    "#import plotly.graph_objects as go\n",
    "#label = [\"Cluster 0\",\"Cluster 1\",\"Cluster 2\",\"Cluster 3\",\"Cluster 0\",\"Cluster 1\",\"Cluster 2\",\"Cluster 3\",\"Cluster 0\",\"Cluster 1\",\"Cluster 2\",\"Cluster 3\",\"Cluster 0\",\"Cluster 1\",\"Cluster 2\",\"Cluster 3\"]\n",
    "#source = [0,0,0,0,1,1,1,1,2,2,2,2,3,3,3,3,4,4,4,4,5,5,5,5,6,6,6,6,7,7,7,7,8,8,8,8]\n",
    "#target =[4,5,6,7,4,5,6,7,4,5,6,7,4,5,6,7,8,9,10,11,8,9,10,11,8,9,10,11,8,9,10,11]\n",
    "#value = [matrix[0][0],matrix[0][1],matrix[0][2],matrix[0][3],matrix[1][0],matrix[1][1],matrix[1][2],matrix[1][3],matrix[2][0],matrix[2][1],matrix[2][2],matrix[2][3],matrix[3][0],matrix[3][1],matrix[3][2],matrix[3][3],matrix1[0][0],matrix1[0][1],matrix1[0][2],matrix1[0][3],matrix1[1][0],matrix1[1][1],matrix1[1][2],matrix1[1][3],matrix1[2][0],matrix1[2][1],matrix1[2][2],matrix1[2][3],matrix1[3][0],matrix1[3][1],matrix1[3][2],matrix1[3][3]]\n",
    "#link=dict(source=source,target=target,value=value)\n",
    "#node= dict(label=label,pad=35, thickness=10)\n",
    "\n",
    "\n",
    "#data=go.Sankey(link=link, node=node)\n",
    "\n",
    "#go.Figure(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fonctions pour projet\n",
    "\n",
    "need to normalize data ? (cf Dissecting financial markets: Sectors and states) (on devrait utiliser les returns donc pas trop besoin de normaliser)\n",
    "- si on cluster les assets, logiquement la correlation/covariance entre chaque cluster devrait être négative/nulle (parce que la distance serait sans doute la covariance entre les assets), du coup faire une stratégie qui investit dans un représentant (asset ou weigted average) de chaque cluster devrait réduire le risque/volatilité du portfolio (problème étant que on aurait pas un zero-cost portfolio), ou alors prédire le signe de return de chaque cluster à la prochaine période et donc investir en fonction)\n",
    "- si on cluster par jour/période de temps, l'idée serait de prédire le futur état et pour chaque état définir une méthode d'investissement\n",
    "- https://d-nb.info/1108447864/34 papier qui parle de cluster les assets: truc important à noter est que les weights pour chaque cluster sont définis par hierarchical clustering p47-48, et les clusters/weights sont recalculés tous les 130 jours (permet d'éviter de refaire les clusters à chaque fois, et en pls ne suppose plus que les clusters restent les memes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
